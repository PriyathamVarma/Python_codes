{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chat-bot-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpZVdOAC888/m4ReSkp4pj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyathamVarma/PriyathamVarma/blob/main/chat_bot_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook is for creating a NLP chatbot."
      ],
      "metadata": {
        "id": "C7mFajU5uU7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the json file bot responses"
      ],
      "metadata": {
        "id": "AAeTiLuOuaBU"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n"
      ],
      "metadata": {
        "id": "q3tOvHqgwjlE"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBePDYLaOtaW",
        "outputId": "da67909f-7d09-4b86-f973-7404cf60bf0e"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "xFgrmpRPxzU1"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents = json.loads(open('/content/sample_data/sample.json').read())"
      ],
      "metadata": {
        "id": "ofR6yBVFx19R"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH7pPv9ryC_0",
        "outputId": "583ba8bb-fa3c-4a2d-80ca-67061da57a80"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inents': [{'patterns': ['hai', 'hello', 'hey'],\n",
              "   'responses': ['hello', 'whats up'],\n",
              "   'tag': 'greetings'},\n",
              "  {'patterns': ['oy', 'hurray', 'voila'],\n",
              "   'responses': ['oyyyy', 'mate'],\n",
              "   'tag': 'answers'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['?',',','.','!']"
      ],
      "metadata": {
        "id": "hM0bKtX7ztLk"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hQe05NfE38s",
        "outputId": "b37b7278-81c7-4276-a279-c267aa79c3d9"
      },
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "waescMcY-lOx"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['inents']:\n",
        "  print(intent)\n",
        "  for patterns in intent['patterns']:\n",
        "    print(patterns)\n",
        "    word_list = nltk.word_tokenize(patterns)\n",
        "    words.extend(word_list)\n",
        "    print(words)\n",
        "    #documents\n",
        "    documents.append((word_list,intent['tag']))\n",
        "    #classes\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DaiJYZP0LtA",
        "outputId": "558e3655-a637-4561-efd2-d5b5aeaa3d50"
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tag': 'greetings', 'patterns': ['hai', 'hello', 'hey'], 'responses': ['hello', 'whats up']}\n",
            "hai\n",
            "['hai']\n",
            "hello\n",
            "['hai', 'hello']\n",
            "hey\n",
            "['hai', 'hello', 'hey']\n",
            "{'tag': 'answers', 'patterns': ['oy', 'hurray', 'voila'], 'responses': ['oyyyy', 'mate']}\n",
            "oy\n",
            "['hai', 'hello', 'hey', 'oy']\n",
            "hurray\n",
            "['hai', 'hello', 'hey', 'oy', 'hurray']\n",
            "voila\n",
            "['hai', 'hello', 'hey', 'oy', 'hurray', 'voila']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOckYVQRFNlv",
        "outputId": "65e5eb14-6af2-4cd5-9ab6-888386ec4b56"
      },
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hai', 'hello', 'hey', 'oy', 'hurray', 'voila']"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g5-btSGGz1D",
        "outputId": "49e6f427-08d7-4768-841f-98e966f76c6a"
      },
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['hai'], 'greetings'),\n",
              " (['hello'], 'greetings'),\n",
              " (['hey'], 'greetings'),\n",
              " (['oy'], 'answers'),\n",
              " (['hurray'], 'answers'),\n",
              " (['voila'], 'answers')]"
            ]
          },
          "metadata": {},
          "execution_count": 408
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gekKAVcw2yCV",
        "outputId": "6b20cbd0-56ae-48c7-ab23-a30595009f24"
      },
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['greetings', 'answers']"
            ]
          },
          "metadata": {},
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lemmatization"
      ],
      "metadata": {
        "id": "u0NBJK-8HIjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_new = []\n",
        "for words in words:\n",
        "  words_new.append(words)\n",
        "  print(words)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dpjl_X2NIdt",
        "outputId": "1cb17fd4-b386-4445-b0f4-868bd995adf3"
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hai\n",
            "hello\n",
            "hey\n",
            "oy\n",
            "hurray\n",
            "voila\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_new"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi1BGrNMOL7A",
        "outputId": "16d309b4-4d91-4771-a60a-ec441f73ba6f"
      },
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hai', 'hello', 'hey', 'oy', 'hurray', 'voila']"
            ]
          },
          "metadata": {},
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words_new if word not in ignore_letters]"
      ],
      "metadata": {
        "id": "s5b0EdyCNWru"
      },
      "execution_count": 412,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(set(lemmatized_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQR51gOQN4dC",
        "outputId": "70f1585e-2e90-427f-cbdc-8a943613d7ac"
      },
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hai', 'hello', 'hey', 'hurray', 'oy', 'voila']"
            ]
          },
          "metadata": {},
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(set(classes))"
      ],
      "metadata": {
        "id": "prkwNzFfO6RH"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvcO5g_PA_0",
        "outputId": "8189c60e-23c7-490f-f0f3-4e5dd0efed8d"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['answers', 'greetings']"
            ]
          },
          "metadata": {},
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ],
      "metadata": {
        "id": "8TRjWv6MPcJV"
      },
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning part"
      ],
      "metadata": {
        "id": "Vikb1dBNPxhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = []\n",
        "output_empty = [0] *len(classes)"
      ],
      "metadata": {
        "id": "AhE4weTJPzIS"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_empty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsruS6vpQeB4",
        "outputId": "b16cddc0-87b9-4290-f8e1-1f8fd2de5982"
      },
      "execution_count": 418,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 418
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iXYb-_nTkEw",
        "outputId": "3e25c623-adb3-4fc0-f210-cf0d449d0291"
      },
      "execution_count": 419,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['hai'], 'greetings'),\n",
              " (['hello'], 'greetings'),\n",
              " (['hey'], 'greetings'),\n",
              " (['oy'], 'answers'),\n",
              " (['hurray'], 'answers'),\n",
              " (['voila'], 'answers')]"
            ]
          },
          "metadata": {},
          "execution_count": 419
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for documents in documents:\n",
        "  bag = []\n",
        "  word_patterns = documents[0]\n",
        "  word_patterns = [lemmatizer.lemmatize(word.lower()) for word in word_patterns]\n",
        "  for word in words:\n",
        "    bag.append(1) if word in word_patterns else bag.append(0)\n",
        "\n",
        "  #output\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(documents[1])] = 1\n",
        "  train.append([bag,output_row])\n"
      ],
      "metadata": {
        "id": "8UKNdd3fP9bV"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(train)\n",
        "training = np.array(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XumnUVYoSEXA",
        "outputId": "b0d8325b-b199-4afc-f25b-b1154649b4fc"
      },
      "execution_count": 421,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ],
      "metadata": {
        "id": "KOluRXm5T2yt"
      },
      "execution_count": 422,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v85fV5CsT-_Y",
        "outputId": "6dab7e53-d695-4371-e8e1-c5a65a652359"
      },
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1], [1, 0], [1, 0], [0, 1], [1, 0], [0, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model development"
      ],
      "metadata": {
        "id": "OwL6d1uLUFQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128,input_shape = (len(train_x[0]),), activation = 'relu' ))"
      ],
      "metadata": {
        "id": "UlwHNEZOPq9P"
      },
      "execution_count": 424,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.5))"
      ],
      "metadata": {
        "id": "S8NRx6YjUm2z"
      },
      "execution_count": 425,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Dense(len(train_y[0]), activation='softmax'))"
      ],
      "metadata": {
        "id": "7HYdXjLJU-BN"
      },
      "execution_count": 426,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = SGD(lr = 0.01, decay = 1e-6 , momentum=0.9,nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=sgd, metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsHmDcyZVHqO",
        "outputId": "4a60b106-3a96-4b08-bc62-c3f7f5cd5b02"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"hist = model.fit(np.array(train_x),np.array(train_y),epochs=100,batch_size = 5, verbose=1)\n",
        "model.save('DS_Bot.model')\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17-rCQfFWRw3",
        "outputId": "248e1849-81a5-4e2f-d11b-580ce63f394e"
      },
      "execution_count": 428,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 0.6935 - accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6996 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7018 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7008 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6924 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6993 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7013 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7039 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7070 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7134 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7129 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7151 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7132 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7096 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7050 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7047 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6987 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6976 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6921 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6916 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6960 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6945 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6963 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7004 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7089 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7083 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7129 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7122 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7123 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7132 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7168 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7207 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7199 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7208 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7228 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7204 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7158 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7141 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7070 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7018 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7019 - accuracy: 0.5000\n",
            "INFO:tensorflow:Assets written to: DS_Bot.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(np.array(train_x),np.array(train_y),epochs=100,batch_size = 5, verbose=1)\n",
        "model.save('DS_Bot.h5',hist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "II6TtI2gbs-b",
        "outputId": "db7fe5f7-fd9e-4c97-eed2-af6d22d82410"
      },
      "execution_count": 437,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6991 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6997 - accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6990 - accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7001 - accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6988 - accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6989 - accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.5000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6927 - accuracy: 0.5000\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6943 - accuracy: 0.5000\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6959 - accuracy: 0.5000\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6950 - accuracy: 0.5000\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6953 - accuracy: 0.5000\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6932 - accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6925 - accuracy: 0.5000\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6949 - accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.6941 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.6940 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.5000\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6969 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6956 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.6977 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6970 - accuracy: 0.5000\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6979 - accuracy: 0.5000\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6964 - accuracy: 0.5000\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6951 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6936 - accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6935 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6957 - accuracy: 0.5000\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6947 - accuracy: 0.5000\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6948 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6954 - accuracy: 0.5000\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6966 - accuracy: 0.5000\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7070 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5000\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7084 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7084 - accuracy: 0.5000\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7098 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.5000\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7082 - accuracy: 0.5000\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.7075 - accuracy: 0.5000\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7054 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7049 - accuracy: 0.5000\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7034 - accuracy: 0.5000\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7032 - accuracy: 0.5000\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.7042 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7080 - accuracy: 0.5000\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7127 - accuracy: 0.5000\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7121 - accuracy: 0.5000\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7133 - accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7110 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.5000\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7029 - accuracy: 0.5000\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7030 - accuracy: 0.5000\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6972 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6946 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6968 - accuracy: 0.5000\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6952 - accuracy: 0.5000\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6942 - accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6937 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BrZjvxaWspW",
        "outputId": "ccd804f8-9af6-408d-b2c5-23df141d797a"
      },
      "execution_count": 429,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7217b74450>"
            ]
          },
          "metadata": {},
          "execution_count": 429
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model development"
      ],
      "metadata": {
        "id": "Pxl4t0KOXsLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = pickle.load(open('/content/words.pkl','rb'))\n",
        "classes = pickle.load(open('/content/classes.pkl','rb'))\n"
      ],
      "metadata": {
        "id": "0hg661AnXthO"
      },
      "execution_count": 430,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic-v9UC_YqvV",
        "outputId": "6d8b96a5-02b9-487e-88e8-ae462cd46042"
      },
      "execution_count": 431,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "2NO40vQBYn26"
      },
      "execution_count": 432,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('/content/DS_Bot.model')"
      ],
      "metadata": {
        "id": "6mi1IUidYayw"
      },
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning the sentence\n",
        "def clean_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word) for word in sentence_words]\n",
        "  return sentence_words"
      ],
      "metadata": {
        "id": "yE6kfFvRYh-5"
      },
      "execution_count": 434,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bag of words\n",
        "def bag_of_words(sentence):\n",
        "  sentence_words = clean_sentence(sentence)\n",
        "  bag = [0] * len(words)\n",
        "\n",
        "  for w in sentence_words:\n",
        "    for i, word in enumerate(words):\n",
        "      if word == w:\n",
        "        bag[i] = 1\n",
        "\n",
        "  return np.array(bag)     \n",
        "\n"
      ],
      "metadata": {
        "id": "qoZ5_VSCZQAj"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_class(sentence):\n",
        "  bagOfWords = bag_of_words(sentence)\n",
        "  res = model.predict(np.array([bagOfWords]))[0]\n",
        "  threshold = 0.25\n",
        "\n",
        "  result = [[i,r] for i,r in enumerate(res) if r> threshold]\n",
        "\n",
        "  result.sort(key=lambda x:x[1], reverse = True)\n",
        "\n",
        "  return_list = []\n",
        "  for r in result:\n",
        "    return_list.append({'intent':classes[r[0]], 'probability':str(r[1])})\n",
        "  return return_list"
      ],
      "metadata": {
        "id": "2pGaaWcUZx7r"
      },
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_res(intents_list,intents_json):\n",
        "  tag = intents_list[0]['intent']\n",
        "  list_of_intents = intents_json['inents']\n",
        "\n",
        "  for i in list_of_intents:\n",
        "    if i['tag'] == tag:\n",
        "      result = random.choice(i['responses'])\n",
        "      break\n",
        "  return result    "
      ],
      "metadata": {
        "id": "ed30Na13dJDF"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  message = input()\n",
        "  ints = predict_class(message)\n",
        "  res = get_res(ints,intents)\n",
        "  print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "niwDPskPbeMa",
        "outputId": "c1e192a2-851e-416a-8472-c05182a91f4b"
      },
      "execution_count": 450,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hai\n",
            "whats up\n",
            "whats your name\n",
            "hello\n",
            "im good\n",
            "hello\n",
            "you\n",
            "whats up\n",
            "i want to know about delays\n",
            "whats up\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-450-3b3e5864c092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_res\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mintents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vKKXQbQVbo8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WozLMctsacqd"
      },
      "execution_count": 436,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GP3BW8xKYWEB"
      },
      "execution_count": 436,
      "outputs": []
    }
  ]
}